{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downoload  lobraries to exceute to colab\n",
    "!pip install pandas numpy scikit-learn kaggle --quiet\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/antoniosstsip/massive-datasets-project/blob/main/project1.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f502556",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Kaggle Dataset Download (Not Executed Locally)\n",
    "‚ö†Ô∏è Due to SSL library limitations on the local environment (macOS with LibreSSL),\n",
    "the dataset was manually downloaded from Kaggle and extracted into the working directory.\n",
    "\n",
    "However, for completeness and reproducibility, the following cell includes\n",
    "the correct code to download the dataset programmatically via the Kaggle API\n",
    "when executed on environments like Google Colab or Linux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API setup --- NOT RUN \n",
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"xxxxxx\"\n",
    "os.environ['KAGGLE_KEY'] = \"xxxxxx\"\n",
    "\n",
    "# Replace with correct dataset ID if needed\n",
    "!kaggle datasets download -d rajeevw/amazon-books-reviews\n",
    "\n",
    "# Unzip (standard location)\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"amazon-books-reviews.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"amazon_books\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d50afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extraction completed\n"
     ]
    }
   ],
   "source": [
    "##  Dataset Download (Kaggle API ‚Äì-- not executed locally)\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "# file path\n",
    "dataset_zip = \"/Users/antonistsipoulakos/Downloads/archive.zip\"\n",
    "\n",
    "# file path for extraction\n",
    "extract_dir = \"/Users/antonistsipoulakos/Desktop/project1/amazon_books\"\n",
    "\n",
    "if os.path.exists(dataset_zip):\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(\"‚úÖ Extraction completed\")\n",
    "else:\n",
    "    print(\"zip file not found.check path and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54bbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999992 reviews loaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review/text\n",
       "0  This is only for Julie Strain fans. It's a col...\n",
       "1  I don't care much for Dr. Seuss but after read...\n",
       "2  If people become the books they read and if \"t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load and preview the dataset (Books_rating.csv)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"/Users/antonistsipoulakos/Desktop/project1/amazon_books/Books_rating.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, usecols=[\"review/text\"])\n",
    "df = df.dropna(subset=[\"review/text\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"{len(df)} reviews loaded.\")\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbddc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 500 reviews processed .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    {pages, fans, collection, find, theres, isnt, ...\n",
       "1    {oh, yeats, industry, hesitate, seussgeisel, c...\n",
       "2    {an, prof, find, via, cubist, avant, verse, is...\n",
       "Name: review/text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocessing: clean and tokenize reviews\n",
    "\n",
    "import re\n",
    "\n",
    "# cleaning function\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()                          # œÄŒµŒ∂Œ¨\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)               # Œ±œÜŒ±ŒØœÅŒµœÉŒ∑ œÉŒ∑ŒºŒµŒØœâŒΩ œÉœÑŒØŒæŒ∑œÇ\n",
    "    return set(text.split())                          # ŒºŒµœÑŒ±œÑœÅŒøœÄŒÆ œÉŒµ œÉœçŒΩŒøŒªŒø ŒªŒ≠ŒæŒµœâŒΩ\n",
    "\n",
    "# sample processing (first 500 reviews)\n",
    "USE_SUBSAMPLE = True\n",
    "N = 500 if USE_SUBSAMPLE else len(df)\n",
    "\n",
    "processed_reviews = df[\"review/text\"][:N].apply(preprocess)\n",
    "\n",
    "print(f\" {N} reviews processed .\")\n",
    "processed_reviews.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd77f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7 pairs found with similarity ‚â• 0.5\n"
     ]
    }
   ],
   "source": [
    "## Compute Jaccard similarity between pairs of reviews\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# (brute-force) calculate Jaccard similarity for all pairs\n",
    "similar_pairs = []\n",
    "threshold = 0.5  # we can change it \n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i + 1, N):\n",
    "        sim = jaccard_similarity(processed_reviews[i], processed_reviews[j])\n",
    "        if sim >= threshold:\n",
    "            similar_pairs.append((i, j, sim))\n",
    "\n",
    "print(f\" {len(similar_pairs)} pairs found with similarity ‚â• {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Pair 162-164 (Similarity: 0.99)\n",
      "üìò Review 1: Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic and Occultism; entirely written for the proverbial 'man about the street', and a very cosmic avenue ...\n",
      "üìò Review 2: Kurt Seligmann, Surrealist artist par excellence, admitted &amp; unashamed bibliophile, has ravaged his occult library in a miraculous marriage giving birth to this classic historical account of Magic and Occultism; entirely written for the proverbial 'man about the street', and a very cosmic avenue ...\n",
      "\n",
      "üîó Pair 198-201 (Similarity: 0.65)\n",
      "üìò Review 1: Dr Baker explains clearly and engagingly how one can improve one's life by changing your subconscious pattern through the spiritual technique called treatment. The essence of treatment is this: When the conscious mind of the individual deliberately selects a creative idea and delivers that idea to t ...\n",
      "üìò Review 2: Dr Baker was one of those great 20th century metaphysicians like Emmet Fox, Ernest Holmes &Thomas Troward, who understood the working of the mind long before psychotherapy became popular. This approach is called \"the religion of healthy mindedness\" by William James in his classicThe Varieties of Rel ...\n",
      "\n",
      "üîó Pair 214-215 (Similarity: 0.91)\n",
      "üìò Review 1: Wonderful! Karen Cummings writes a book that tells you all the basics in cat care and tailors it to the Birman breed. The excellent photographs enable the reader to see what a Birmans really looks like. The history of the Birman, (Sacred cat of Burma), it's mythic legend is beautifully illustrated i ...\n",
      "üìò Review 2: Wonderful! Karen Cummings writes a book that tells you all thebasics of cat care and tailors it to the Birman breed. The excellentphotographs enable the reader to see what a Birman really looks like. The history of the Birman, (Sacred cat of Burma), it's mythic legend is beautifully illustrated in t ...\n",
      "\n",
      "üîó Pair 253-256 (Similarity: 1.00)\n",
      "üìò Review 1: King James by Ryan Jones is a biography of Lebron's James' life prior to going into the NBA. It tells about how a little kid who lived in poverty with his mother goes on to become a six foot eight inch 245 pound high school basketball superstar. Lebron has to deal with the pressure of the media and  ...\n",
      "üìò Review 2: King James by Ryan Jones is a biography of Lebron's James' life prior to going into the NBA. It tells about how a little kid who lived in poverty with his mother goes on to become a six foot eight inch 245 pound high school basketball superstar. Lebron has to deal with the pressure of the media and  ...\n",
      "\n",
      "üîó Pair 262-267 (Similarity: 1.00)\n",
      "üìò Review 1: DE LUCHA Y TRIUNFO..ESTE LIBRO TE DEJAR&Aacute; MUY SATISFECHO...Aunque no seas aficionado al box! ...\n",
      "üìò Review 2: DE LUCHA Y TRIUNFO..ESTE LIBRO TE DEJAR&Aacute; MUY SATISFECHO...Aunque no seas aficionado al box! ...\n"
     ]
    }
   ],
   "source": [
    "##  Display similar review pairs\n",
    "\n",
    "# Show first 5 similar pairs\n",
    "for i, j, sim in similar_pairs[:5]:\n",
    "    print(f\"\\nPair {i}-{j} (Similarity: {sim:.2f})\")\n",
    "    print(\"üìò Review 1:\", df[\"review/text\"][i][:300], \"...\")\n",
    "    print(\"üìò Review 2:\", df[\"review/text\"][j][:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28762ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsampling: control execution time and scalability\n",
    "\n",
    "To ensure scalability and fast execution, especially in environments like Google Colab, we use a global flag `USE_SUBSAMPLE`.\n",
    "If `True`, only a small subset of the dataset is used (default: 100 reviews).  \n",
    "If `False`, the entire dataset is processed.\n",
    "\n",
    "This allows us to demonstrate correctness on small samples while ensuring that the code can scale up easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbd277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a sample of 100 reviews.\n",
      "‚úÖ Preprocessed 100 reviews.\n",
      "‚úÖ Found 0 pairs with similarity ‚â• 0.5\n"
     ]
    }
   ],
   "source": [
    "# Global toggle for subsampling\n",
    "import re\n",
    "\n",
    "USE_SUBSAMPLE = True     # Set to False to process the full dataset\n",
    "SAMPLE_SIZE = 100        # Number of reviews to use when subsampling\n",
    "\n",
    "# üß™ Select data size based on toggle\n",
    "N = SAMPLE_SIZE if USE_SUBSAMPLE else len(df)\n",
    "\n",
    "# Show what is being processed\n",
    "print(f\"Processing {'a sample of' if USE_SUBSAMPLE else 'all'} {N} reviews.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing function: lowercase, remove punctuation, tokenize\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return set(text.split())\n",
    "\n",
    "# Apply preprocessing to selected reviews\n",
    "processed_reviews = df[\"review/text\"][:N].apply(preprocess)\n",
    "print(f\"‚úÖ Preprocessed {N} reviews.\")\n",
    "\n",
    "\n",
    "\n",
    "# Jaccard similarity function\n",
    "def jaccard_similarity(set1, set2):\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# Compute similar review pairs\n",
    "threshold = 0.5\n",
    "similar_pairs = []\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i + 1, N):\n",
    "        sim = jaccard_similarity(processed_reviews[i], processed_reviews[j])\n",
    "        if sim >= threshold:\n",
    "            similar_pairs.append((i, j, sim))\n",
    "\n",
    "print(f\"‚úÖ Found {len(similar_pairs)} pairs with similarity ‚â• {threshold}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49aa64ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîù Top 5 Similar Reviews:\n",
      "\n",
      "#1 - Similarity: 0.247\n",
      "Review 21: I loved Whisper of the wicked saints. The story was amazing and I was pleasantly surprised at the changes in the book. I am not normaly someone who is into romance novels, but the world was raving abo...\n",
      "Review 31: I happen to love romance novels, but only if they are goos romance. I am not one who loves everything, but this made my heart rejoice. I absolutlely could not put it down. Wow what a book !! You have ...\n",
      "\n",
      "#2 - Similarity: 0.230\n",
      "Review 18: I read the review directly under mine and I have to say I laughed. How can someone write a honest review on a book they read only three pages of? That was funny but also sad that people are mean enoug...\n",
      "Review 21: I loved Whisper of the wicked saints. The story was amazing and I was pleasantly surprised at the changes in the book. I am not normaly someone who is into romance novels, but the world was raving abo...\n",
      "\n",
      "#3 - Similarity: 0.225\n",
      "Review 50: This is a very useful and thorough text book. I would recommend it for anyone who wants an in depth study of the Lord's church....\n",
      "Review 75: Many useful concepts of digital compression can be found in this book. It is easy to read and understand, especially for students and engineers in EE....\n",
      "\n",
      "#4 - Similarity: 0.218\n",
      "Review 20: This was not a typical romance read. It is deep, loving and full of suspense. This book touches on wemon's issues and it caresses the heart. By the third chapter I was hooked. I did not think the firs...\n",
      "Review 50: This is a very useful and thorough text book. I would recommend it for anyone who wants an in depth study of the Lord's church....\n",
      "\n",
      "#5 - Similarity: 0.218\n",
      "Review 21: I loved Whisper of the wicked saints. The story was amazing and I was pleasantly surprised at the changes in the book. I am not normaly someone who is into romance novels, but the world was raving abo...\n",
      "Review 29: I am an avid reader and I was shocked at how hooked I became on this book. I thought the first chapter was a little long and a little too discriptive, but truth be told after that I could not put this...\n"
     ]
    }
   ],
   "source": [
    "# Jaccard similarity œÖœÄŒøŒªŒøŒ≥ŒπœÉŒºŒ≠ŒΩŒø \"from scratch\"\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"calculates the Jaccard similarity between two sets of words.\"\"\"\n",
    "    intersection = set1 & set2\n",
    "    union = set1 | set2\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "# === calculate similarities for all reviews ===\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "\n",
    "# use only the first 100 reviews\n",
    "SAMPLE_SIZE = 100\n",
    "reviews = df[\"review/text\"].head(SAMPLE_SIZE).tolist()\n",
    "\n",
    "# Convert to sets of words (tokens)\n",
    "tokenized_reviews = [set(str(r).lower().split()) for r in reviews]\n",
    "\n",
    "# Compute similarities for each pair\n",
    "similarities = []\n",
    "for i, j in combinations(range(len(tokenized_reviews)), 2):\n",
    "    sim = jaccard_similarity(tokenized_reviews[i], tokenized_reviews[j])\n",
    "    similarities.append(((i, j), sim))\n",
    "\n",
    "# Œ§Œ±ŒæŒπŒΩœåŒºŒ∑œÉŒ∑ Œ∫Œ±œÑŒ¨ score œÜŒ∏ŒØŒΩŒøœÖœÉŒ±\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print top 5 similar reviews\n",
    "print(\"\\nüîù Top 5 Similar Reviews:\")\n",
    "for idx, ((i, j), score) in enumerate(similarities[:5], 1):\n",
    "    print(f\"\\n#{idx} - Similarity: {score:.3f}\")\n",
    "    print(f\"Review {i}: {reviews[i][:200]}...\")\n",
    "    print(f\"Review {j}: {reviews[j][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
